#!/usr/bin/env bash
set -eu -o pipefail

#
# Called by the worker processes for each queue'd item
#
function process_item {
  local worker_id="$1"
  local item="$2"

  # Simulate processing time
  min_processing_time=1
  max_processing_time=3
  sleep $((min_processing_time + RANDOM % (min_processing_time - max_processing_time)))

  printf >&2 "** completed: worker-id=%d, item=%s\n" "$worker_id" "$item"
}

# Coordination files
START="$(      mktemp -t 'start' )"
START_LOCK="$( mktemp -t 'lock'  )"
FIFO="$(       mktemp -t 'fifo'  )"
FIFO_LOCK="$(  mktemp -t 'lock'  )"
cat >&2 <<EOF

Coordination Files:
  start        -> ${START}
  start (lock) -> ${START_LOCK}
  fifo         -> ${FIFO}
  fifo (lock)  -> ${FIFO_LOCK}

EOF

# [mktemp] makes a regular file, using the same path - recreate as a [fifo].
rm "$FIFO"
mkfifo "$FIFO"

#
# Cleanup coordination files on exit.
#
function cleanup {
  printf >&2 "\nCleaning up coordination files ...\n\n"

  rm "$FIFO"
  rm "$START"
  rm "$FIFO_LOCK"
  rm "$START_LOCK"
}
trap cleanup 0

#
# Queue Worker
#
function queue_worker {
  local worker_id="$1"

  # Open the fifo and locks for reading as additional file descriptors
  exec 3<"$FIFO"
  exec 4<"$FIFO_LOCK"
  exec 5<"$START_LOCK"

  # Signal the worker has started.
  flock 5                        # obtain the [start file] lock
  echo "$worker_id" >> "$START"  # put my worker ID in the start file
  flock -u 5                     # release the start file lock
  printf >&2 "%2d: queue worker started.\n" "$worker_id"

  while true; do
    # attempt to read from the queue
    flock 4                       # obtain the [fifo] lock
    read -rsu 3 work_id work_item # read+parse item line parts from the fifo
    read_status="$?"              # save the exit status of read
    flock -u 4                    # release the [fifo] lock

    # check the line read, 0 if the read succeeded.
    if [[ "$read_status" -eq "0" ]]; then
      printf >&2 "<= %2d: processing received queued item, id=%d, item=%s ...\n" \
        "$worker_id" "$work_id" "$work_item"
      # Run the work item in a subshell.
      # Protects the worker process from [exit] calls
      (process_item "$worker_id" "$work_id" "$work_item")
    else
      # Any other read exit code indicates an EOF (queue is empty).
      printf >&2 "%2d: queue is empty, shutting down ...\n" "$worker_id"
      break
    fi
  done

  # Clean up the file descriptors
  exec 3<&-
  exec 4<&-
  exec 5<&-
  printf >&2 "%2d: shutdown.\n" "$worker_id"
}

# 1 queue worker per logical processor.
num_procs="$(getconf "_NPROCESSORS_ONLN")"
worker_count="$num_procs"
# Start the concurrent queue workers
for ((worker_id=1; worker_id <= worker_count; worker_id++)); do
  queue_worker "$worker_id" &
done

# Open the queue (fifo) for writing.
exec 3>"$FIFO"

# Open the (start file) lock for reading
exec 4<"$START_LOCK"

# Spin/wait for the queue workers to start
while true; do
  flock 4
  started="$(wc -l < "$START")"
  flock -u 4
  if [[ "$started" -eq "$worker_count" ]]; then
    printf >&2 "\nAll queue workers ready.\n\n"
    break
  else
    sleep 1
  fi
done

# Close the (start file) lock file descriptor
exec 4<&-

# Produce and enqueue the items to process.
item_count="$((worker_count * 3))"
for id in $(seq "$item_count"); do
  # Queue item: id, timestamp
  item="$(date "+%Y-%m-%d_%H:%M:%S:%N_%Z_%s")"

  printf >&2 "=> Enqueueing item: id=%d, item=%s\n" "$id" "$item"

  # Write to the queue (fifo) - file descriptor (3).
  echo "${id} ${item}" 1>&3
done

# Close the queue (fifo) file descriptor
exec 3<&-

# Wait for workers to drain the queue and shutdown.
wait
